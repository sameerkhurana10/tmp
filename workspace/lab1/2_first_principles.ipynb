{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name:\n",
    "-your-name-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: MNIST: First Principles\n",
    "\n",
    "In this notebook, we will recreate the functions that PyTorch provides for the individual layers in our network using primtive Python code. The goal of this notebook is to understand what happens in a network underneath the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MNIST test data as numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test set using torchvision\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1)\n",
    "\n",
    "# convert to numpy array\n",
    "images_array = torch.zeros((10000,28,28))\n",
    "labels_array = torch.zeros(10000)\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    image, label = data\n",
    "    images_array[i,:,:] = image\n",
    "    labels_array[i] = label\n",
    "images_array = images_array.numpy()\n",
    "labels_array = labels_array.numpy()\n",
    "labels_array = labels_array.astype(int)\n",
    "print(images_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.\n",
    "\n",
    "Visualize the first test image and label.\n",
    "\n",
    "Load the model parameters (the file you saved in pytorch.ipynb). Similarly visualize the weights of the filters used in the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have saved model_parameters.npy\n",
    "model_parameters = np.load('my_model_parameters.npy', allow_pickle=True)\n",
    "model_parameters = model_parameters[()]\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "# Your code to display one input image here (with its label)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "l1_filter = np.zeros((1,1,1,1)) # update\n",
    "\n",
    "num_input_channels = l1_filter.shape[1]\n",
    "num_out_channels = l1_filter.shape[0] # filters\n",
    "plt.figure(2)\n",
    "for x in range(num_out_channels): # filters\n",
    "    for y in range(num_input_channels): # channels\n",
    "        plt.subplot(num_input_channels, num_out_channels, y*num_out_channels + x + 1)\n",
    "        # Your code for the filter here\n",
    "        \n",
    "        plt.title(\"In: %d, Out: %d\" % (y, x))\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the network\n",
    "\n",
    "### Question 10.\n",
    "\n",
    "We need to write code to run the individual layers in our network. For simiplicity, assume that the batch size is 1, i.e., the activation layers are numpy arrays with shape (channels, height, width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, W, b):\n",
    "    # Your code here\n",
    "    return np.array([])\n",
    "\n",
    "def fc(x, W, b):\n",
    "    # Your code here\n",
    "    return np.array([])\n",
    "\n",
    "def relu(x):\n",
    "    # Your code here\n",
    "    return np.array([])\n",
    "\n",
    "def pool2(x, dh, dw):\n",
    "    # Your code here\n",
    "    return np.array([])\n",
    "\n",
    "def flatten(x):\n",
    "    # Your code here\n",
    "    return np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11.\n",
    "\n",
    "Compose the layers from above to create the network from `mnist/pytorch.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image, model_parameters):\n",
    "    # Your code for defining the correct network topology here, using the saved model parameters\n",
    "    # replace code below\n",
    "    l1 = conv(np.array([]), np.array([]), np.array([]))\n",
    "    l2 = pool2(l1, 1, 1)\n",
    "    l3 = fc(l2, np.array([]), np.array([]))\n",
    "    output_class = 0 # calculate output label here\n",
    "    return output_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to verify your network on the first 1000 images from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total = (0, 1000)\n",
    "for n in tqdm(range(min(total, int(images_array.shape[0])))):\n",
    "    inference = run_inference(images_array[n], model_parameters)\n",
    "    if labels_array[n] == inference:\n",
    "        correct += 1\n",
    "print(\"Accuracy: %d/%d (%.2g)\" % (correct, total, float(correct)/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12.\n",
    "You have built a programmable system that performs classification on MNIST, where the input image size is 28x28 @ 95% accuracy. It only spends 0.1nJ per classification and operates at 100 classifications per second. You then use it to perform classification on ImageNet, where the input image size is 224x224 @ 95% accuracy. However, you noticed that the energy and latency scale much more than 224x224/(28x28). What could be causing the non-linear scaling? Answer in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-your-answer-here-\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
